digraph {
	graph [size="34.05,34.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140043533016016 [label="
 (1, 1, 128, 128)" fillcolor=darkolivegreen1]
	140043519045296 [label=ConvolutionBackward0]
	140043519045344 -> 140043519045296
	140043519045344 [label=LeakyReluBackward1]
	140043519111376 -> 140043519045344
	140043519111376 [label=CudnnBatchNormBackward0]
	140043519111472 -> 140043519111376
	140043519111472 [label=ConvolutionBackward0]
	140043519111664 -> 140043519111472
	140043519111664 [label=LeakyReluBackward1]
	140043519111808 -> 140043519111664
	140043519111808 [label=CudnnBatchNormBackward0]
	140043519111904 -> 140043519111808
	140043519111904 [label=ConvolutionBackward0]
	140043519112096 -> 140043519111904
	140043519112096 [label=CatBackward0]
	140043519112240 -> 140043519112096
	140043519112240 [label=ConvolutionBackward0]
	140043519112384 -> 140043519112240
	140043519112384 [label=LeakyReluBackward1]
	140043519112576 -> 140043519112384
	140043519112576 [label=CudnnBatchNormBackward0]
	140043519112672 -> 140043519112576
	140043519112672 [label=ConvolutionBackward0]
	140043519112864 -> 140043519112672
	140043519112864 [label=LeakyReluBackward1]
	140043519113008 -> 140043519112864
	140043519113008 [label=CudnnBatchNormBackward0]
	140043519113104 -> 140043519113008
	140043519113104 [label=ConvolutionBackward0]
	140043519113296 -> 140043519113104
	140043519113296 [label=CatBackward0]
	140043519113440 -> 140043519113296
	140043519113440 [label=ConvolutionBackward0]
	140043519113584 -> 140043519113440
	140043519113584 [label=MulBackward0]
	140043519113776 -> 140043519113584
	140043519113776 [label=LeakyReluBackward1]
	140043519113872 -> 140043519113776
	140043519113872 [label=CudnnBatchNormBackward0]
	140043519113968 -> 140043519113872
	140043519113968 [label=ConvolutionBackward0]
	140043519114160 -> 140043519113968
	140043519114160 [label=LeakyReluBackward1]
	140043519114304 -> 140043519114160
	140043519114304 [label=CudnnBatchNormBackward0]
	140043519114400 -> 140043519114304
	140043519114400 [label=ConvolutionBackward0]
	140043519114592 -> 140043519114400
	140043519114592 [label=MaxPool2DWithIndicesBackward0]
	140043519113392 -> 140043519114592
	140043519113392 [label=LeakyReluBackward1]
	140043519114784 -> 140043519113392
	140043519114784 [label=CudnnBatchNormBackward0]
	140043519114880 -> 140043519114784
	140043519114880 [label=ConvolutionBackward0]
	140043519115072 -> 140043519114880
	140043519115072 [label=LeakyReluBackward1]
	140043519115216 -> 140043519115072
	140043519115216 [label=CudnnBatchNormBackward0]
	140043519115120 -> 140043519115216
	140043519115120 [label=ConvolutionBackward0]
	140043519119664 -> 140043519115120
	140043519119664 [label=MaxPool2DWithIndicesBackward0]
	140043519112192 -> 140043519119664
	140043519112192 [label=LeakyReluBackward1]
	140043519119856 -> 140043519112192
	140043519119856 [label=CudnnBatchNormBackward0]
	140043519119952 -> 140043519119856
	140043519119952 [label=ConvolutionBackward0]
	140043519120144 -> 140043519119952
	140043519120144 [label=LeakyReluBackward1]
	140043519120288 -> 140043519120144
	140043519120288 [label=CudnnBatchNormBackward0]
	140043519120384 -> 140043519120288
	140043519120384 [label=ConvolutionBackward0]
	140043519120576 -> 140043519120384
	140043519581376 [label="
 (1, 4, 128, 128)" fillcolor=lightblue]
	140043519581376 -> 140043519120576
	140043519120576 [label=AccumulateGrad]
	140043519120528 -> 140043519120384
	140043533016176 [label="encoder1.block.0.weight
 (64, 4, 3, 3)" fillcolor=lightblue]
	140043533016176 -> 140043519120528
	140043519120528 [label=AccumulateGrad]
	140043519120336 -> 140043519120288
	140043533016576 [label="encoder1.block.1.weight
 (64)" fillcolor=lightblue]
	140043533016576 -> 140043519120336
	140043519120336 [label=AccumulateGrad]
	140043519120192 -> 140043519120288
	140043533016096 [label="encoder1.block.1.bias
 (64)" fillcolor=lightblue]
	140043533016096 -> 140043519120192
	140043519120192 [label=AccumulateGrad]
	140043519120096 -> 140043519119952
	140043533674032 [label="encoder1.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140043533674032 -> 140043519120096
	140043519120096 [label=AccumulateGrad]
	140043519119904 -> 140043519119856
	140043786554080 [label="encoder1.block.4.weight
 (64)" fillcolor=lightblue]
	140043786554080 -> 140043519119904
	140043519119904 [label=AccumulateGrad]
	140043519119760 -> 140043519119856
	140043521451088 [label="encoder1.block.4.bias
 (64)" fillcolor=lightblue]
	140043521451088 -> 140043519119760
	140043519119760 [label=AccumulateGrad]
	140043519119616 -> 140043519115120
	140043521437504 [label="encoder2.block.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140043521437504 -> 140043519119616
	140043519119616 [label=AccumulateGrad]
	140043519119472 -> 140043519115216
	140043521437104 [label="encoder2.block.1.weight
 (128)" fillcolor=lightblue]
	140043521437104 -> 140043519119472
	140043519119472 [label=AccumulateGrad]
	140043519119424 -> 140043519115216
	140043521529152 [label="encoder2.block.1.bias
 (128)" fillcolor=lightblue]
	140043521529152 -> 140043519119424
	140043519119424 [label=AccumulateGrad]
	140043519115024 -> 140043519114880
	140043520099168 [label="encoder2.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140043520099168 -> 140043519115024
	140043519115024 [label=AccumulateGrad]
	140043519114832 -> 140043519114784
	140043520099648 [label="encoder2.block.4.weight
 (128)" fillcolor=lightblue]
	140043520099648 -> 140043519114832
	140043519114832 [label=AccumulateGrad]
	140043519114688 -> 140043519114784
	140043520099088 [label="encoder2.block.4.bias
 (128)" fillcolor=lightblue]
	140043520099088 -> 140043519114688
	140043519114688 [label=AccumulateGrad]
	140043519114544 -> 140043519114400
	140043519580976 [label="bottleneck.block.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140043519580976 -> 140043519114544
	140043519114544 [label=AccumulateGrad]
	140043519114352 -> 140043519114304
	140043519580896 [label="bottleneck.block.1.weight
 (256)" fillcolor=lightblue]
	140043519580896 -> 140043519114352
	140043519114352 [label=AccumulateGrad]
	140043519114208 -> 140043519114304
	140043519580176 [label="bottleneck.block.1.bias
 (256)" fillcolor=lightblue]
	140043519580176 -> 140043519114208
	140043519114208 [label=AccumulateGrad]
	140043519114112 -> 140043519113968
	140043519581136 [label="bottleneck.block.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140043519581136 -> 140043519114112
	140043519114112 [label=AccumulateGrad]
	140043519113920 -> 140043519113872
	140043519603632 [label="bottleneck.block.4.weight
 (256)" fillcolor=lightblue]
	140043519603632 -> 140043519113920
	140043519113920 [label=AccumulateGrad]
	140043519113680 -> 140043519113872
	140043519604112 [label="bottleneck.block.4.bias
 (256)" fillcolor=lightblue]
	140043519604112 -> 140043519113680
	140043519113680 [label=AccumulateGrad]
	140043519113536 -> 140043519113440
	140043519633584 [label="up2.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	140043519633584 -> 140043519113536
	140043519113536 [label=AccumulateGrad]
	140043519113488 -> 140043519113440
	140043519634944 [label="up2.bias
 (128)" fillcolor=lightblue]
	140043519634944 -> 140043519113488
	140043519113488 [label=AccumulateGrad]
	140043519113392 -> 140043519113296
	140043519113248 -> 140043519113104
	140043519635344 [label="decoder2.block.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	140043519635344 -> 140043519113248
	140043519113248 [label=AccumulateGrad]
	140043519113056 -> 140043519113008
	140043519758400 [label="decoder2.block.1.weight
 (128)" fillcolor=lightblue]
	140043519758400 -> 140043519113056
	140043519113056 [label=AccumulateGrad]
	140043519112912 -> 140043519113008
	140043519758480 [label="decoder2.block.1.bias
 (128)" fillcolor=lightblue]
	140043519758480 -> 140043519112912
	140043519112912 [label=AccumulateGrad]
	140043519112816 -> 140043519112672
	140043519758880 [label="decoder2.block.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140043519758880 -> 140043519112816
	140043519112816 [label=AccumulateGrad]
	140043519112624 -> 140043519112576
	140043519759040 [label="decoder2.block.4.weight
 (128)" fillcolor=lightblue]
	140043519759040 -> 140043519112624
	140043519112624 [label=AccumulateGrad]
	140043519112480 -> 140043519112576
	140043519758960 [label="decoder2.block.4.bias
 (128)" fillcolor=lightblue]
	140043519758960 -> 140043519112480
	140043519112480 [label=AccumulateGrad]
	140043519112336 -> 140043519112240
	140043519759360 [label="up1.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	140043519759360 -> 140043519112336
	140043519112336 [label=AccumulateGrad]
	140043519112288 -> 140043519112240
	140043519759440 [label="up1.bias
 (64)" fillcolor=lightblue]
	140043519759440 -> 140043519112288
	140043519112288 [label=AccumulateGrad]
	140043519112192 -> 140043519112096
	140043519112048 -> 140043519111904
	140043519759600 [label="decoder1.block.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	140043519759600 -> 140043519112048
	140043519112048 [label=AccumulateGrad]
	140043519111856 -> 140043519111808
	140043519759680 [label="decoder1.block.1.weight
 (64)" fillcolor=lightblue]
	140043519759680 -> 140043519111856
	140043519111856 [label=AccumulateGrad]
	140043519111712 -> 140043519111808
	140043519759760 [label="decoder1.block.1.bias
 (64)" fillcolor=lightblue]
	140043519759760 -> 140043519111712
	140043519111712 [label=AccumulateGrad]
	140043519111616 -> 140043519111472
	140043519760160 [label="decoder1.block.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140043519760160 -> 140043519111616
	140043519111616 [label=AccumulateGrad]
	140043519111424 -> 140043519111376
	140043519760240 [label="decoder1.block.4.weight
 (64)" fillcolor=lightblue]
	140043519760240 -> 140043519111424
	140043519111424 [label=AccumulateGrad]
	140043519111232 -> 140043519111376
	140043519760320 [label="decoder1.block.4.bias
 (64)" fillcolor=lightblue]
	140043519760320 -> 140043519111232
	140043519111232 [label=AccumulateGrad]
	140043519045488 -> 140043519045296
	140043519760720 [label="final_conv.weight
 (1, 64, 1, 1)" fillcolor=lightblue]
	140043519760720 -> 140043519045488
	140043519045488 [label=AccumulateGrad]
	140043519045248 -> 140043519045296
	140043519760800 [label="final_conv.bias
 (1)" fillcolor=lightblue]
	140043519760800 -> 140043519045248
	140043519045248 [label=AccumulateGrad]
	140043519045296 -> 140043533016016
}
